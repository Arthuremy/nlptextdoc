{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy tokenization\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "https://spacy.io/usage/linguistic-features#how-tokenizer-works\n",
    "\n",
    "1. The text is split on **whitespace characters**, similar to text.split(' '). \n",
    "\n",
    "*Whitespace characters are those characters defined in the Unicode character database as “Other” or “Separator” and those with bidirectional property being one of “WS”, “B”, or “S”.*\n",
    "\n",
    "2. The tokenizer processes the text from left to right : on each substring, it performs three checks\n",
    "\n",
    "\n",
    "3. Does the substring match patterns of **tokens that should never be split** ?\n",
    "\n",
    "*For example URLs or numbers.*\n",
    "\n",
    "4. Does the substring match **special cases** of the tokenizer ? \n",
    "\n",
    "*For example, “don’t” doesn't contain a whitespace, but should be split into two tokens : “do” and “n’t”, while “U.K.” should always remain one token.*\n",
    "\n",
    "5. Can a **prefix**, **suffix** or **infix** be split off (in this order) ?\n",
    "\n",
    "*For example punctuation like commas, periods, hyphens or quotes.*\n",
    "\n",
    "6. If we consume a prefix, suffix or infix, go back to step 3 (so that exeptions always get priority).\n",
    "\n",
    "\n",
    "7. Return a token if there is no more prefix, suffix or infix to consume.\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/tokenizer.pyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "https://spacy.io/usage/linguistic-features#native-tokenizers\n",
    "\n",
    "Configuration elements :\n",
    "\n",
    "- Special cases : contractions, units of measurement, emoticons, certain abbreviations, etc.\n",
    "- Preceding punctuation\t: open quotes, open brackets, ...\n",
    "- Succeeding punctuation : commas, periods, close quotes, ...\n",
    "- Infixes :\tnon-whitespace separators, such as hyphens ...\n",
    "- Boolean function token_match : matching strings that should never be split, overriding the previous rules. Useful for things like URLs or numbers.\n",
    "\n",
    "Two levels of configuration :\n",
    "\n",
    "- Base data : char classes, prefixes/suffixes/infixes, tokenizer exceptions\n",
    "- Language data (en,fr,de,es) : prefixes/suffixes/infixes, tokenizer exceptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base data\n",
    "\n",
    "### Char classes\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/char_classes.py\n",
    "\n",
    "https://unicode-table.com/en/blocks/\n",
    "\n",
    "```\n",
    "LATIN_BASIC = _latin_standard + _latin_standard_fullwidth + _latin_supplement + _latin_extendedA      \n",
    "\n",
    "LATIN_LOWER_BASIC, LATIN_UPPER_BASIC\n",
    "\n",
    "LATIN = LATIN_BASIC + _latin_extendedB + _latin_extendedC + _latin_extendedD + _latin_extendedE + _latin_phonetic + _latin_diacritics         \n",
    "\n",
    "LATIN_LOWER, LATIN_UPPER\n",
    "\n",
    "ALPHA = LATIN + _russian + _tatar + _greek + _ukrainian + _bengali + _hebrew + _persian + _sinhala + _hindi\n",
    "\n",
    "ALPHA_LOWER, ALPHA_UPPER\n",
    "\n",
    "UNITS = km km² km³ m m² m³ dm dm² dm³ cm cm² cm³ mm mm² mm³ ha µm nm yd in ft kg g mg µg t lb oz m/s km/h kmh mph hPa Pa mbar mb MB kb KB gb GB tb TB T G M K % км км² км³ м м² м³ дм дм² дм³ см см² см³ мм мм² мм³ нм ...non latin...\n",
    "\n",
    "CURRENCY = $ £ € ¥ ฿ US$ C$ A$ ₽ ﷼ ₴\n",
    "\n",
    "QUOTES = ' \" ” “ ` ‘ ´ ’ ‚ , „ » « 「 」 『 』 （ ） 〔 〕 【 】 《 》 〈 〉\n",
    "\n",
    "PUNCT = … …… , : ; ! ? ¿ ؟ ¡ ( ) [ ] { } < > _ # \\* & 。 ？ ！ ， 、 ； ： ～ · । ، ۔ ؛ ٪\n",
    "\n",
    "HYPHENS = - – — -- --- —— ~\n",
    "\n",
    "ELLIPSES = ..+ …\n",
    "\n",
    "ICONS = Various symbols like dingbats, but also emoji\n",
    "```\n",
    "\n",
    "Notes :\n",
    "- CURRENCY - unicode symbols : 36 Dollar Sign | 163 Pound Sign | 8364 Euro Sign | 165 Yen Sign | 3647 Thai Currency Symbol Baht | 8381 Ruble Symbol | 65020 Rial Sign | 8372 Hryvnia Sign \n",
    "\n",
    "=> CURRENCY misses many symbols from https://unicode-table.com/en/blocks/currency-symbols/\n",
    "\n",
    "\n",
    "- QUOTES - unicode symbols : 39 Apostrophe | 34 Quotation Mark | 8221 Right Double Quotation Mark | 8220 Left Double Quotation Mark | 96 Grave Accent | 180 Acute Accent | 8216 Left Single Quotation Mark | 8217 Right Single Quotation Mark | 8218 Single Low-9 Quotation Mark | 44 Comma | 8222 Double Low-9 Quotation Mark | 187 Right-Pointing Double Angle Quotation Mark | 171 Left-Pointing Double Angle Quotation Mark | 12300 Left Corner Bracket | 12301 Right Corner Bracket | 12302 Left White Corner Bracket | 12303 Right White Corner Bracket | 65288 Fullwidth Left Parenthesis | 65289 Fullwidth Right Parenthesis | 12308 Left Tortoise Shell Bracket | 12309 Right Tortoise Shell Bracket | 12304 Left Black Lenticular Bracket | 12305 Right Black Lenticular Bracket | 12288 Left Double Angle Bracket | 12299 Right Double Angle Bracket | 12296 Left Angle Bracket | 12297 Right Angle Bracket\n",
    "\n",
    "\n",
    "- PUNCT - unicode symbols : 8230 Horizontal Ellipsis (1x 2x) | 44 Comma | 58 Colon | 59 Semicolon | 33 Exclamation Mark | 63 Question Mark | 191 Inverted Question Mark | 1567 Arabic Question Mark | 161 Inverted Exclamation Mark | 40 Left Parenthesis | 41 Right Parenthesis | 91 Left Square Bracket | 93 Right Square Bracket | 123 Left Curly Bracket | 125 Right Curly Bracket | 60 Less-Than Sign | 62 Greater-Than Sign | 95 Low Line | 35 Number Sign | 42 Asterisk | 38 Ampersand | 12290 Ideographic Full Stop | 65311 Fullwidth Question Mark | 65281 Fullwidth Exclamation Mark | 65292 Fullwidth Comma | 12289 Ideographic Comma | 65307 Fullwidth Semicolon | 65306 Fullwidth Colon | 65374 Fullwidth Tilde | 183 Middle Dot | 2404 Devanagari Danda | 1548 Arabic Comma | 1563 Arabic Semicolon | 1748 Arabic Full Stop | 1642 Arabic Percent Sign\n",
    "\n",
    "=> PUNCT doesn't contain . or +\n",
    "\n",
    "- HYPHENS - unicode symbols : 45 Hyphen-Minus (1x 2x 3x) | 8211 En Dash | 8212 Em Dash (1x 2x) | 126 Tilde\n",
    "\n",
    "\n",
    "- ELLIPSES - unicode symbols : 8230 Horizontal Ellipsis\n",
    "\n",
    "\n",
    "- ICONS - list of symbols : https://www.compart.com/en/unicode/category/So"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefixes\n",
    "\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/punctuation.py\n",
    "\n",
    "- punct, ellipses, quotes, currency, icons\n",
    "- \"§\" (167 Section Sign), \"%\", \"=\", \"—\" (8212 Em Dash), \"–\" (8211 En Dash)\n",
    "- \"+\" not followed by a number : \"\\+(?![0-9])+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffixes\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/punctuation.py\n",
    "    \n",
    "- punct, ellipses, quotes, icons\n",
    "- english suffixes : \"'s\", \"'S\", \"’s\", \"’S\"\n",
    "- \"—\" (8212 Em Dash), \"–\" (8211 En Dash)\n",
    "- \"+\" preceded by numbers : \"(?<=[0-9])\\+\"\t\t\n",
    "- \".\" preceded by temperature : \"(?<=°[FfCcKk])\\.\"\t\t\n",
    "- \".\" preceded by alphanumeric lower, \"%\" \"²\" \"-\" \"+\", quotes : \"(?<=[0-9{al}{e}(?:{q})])\\.\"\n",
    "- \".\" preceded by at least two alphabetic upper : \"(?<=[{au}][{au}])\\.\"\t\t\n",
    "- currency preceded by number : \"(?<=[0-9])(?:{c})\"\t\t\n",
    "- unit preceded by number : (?<=[0-9])(?:{u})\"\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infixes\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/punctuation.py\n",
    "\n",
    "- ellipses, icons\n",
    "- \"+\" \"-\" \"\\*\" \"^\" preceded by number and followed by number or \"-\" : \"(?<=[0-9])[+\\-\\*^](?=[0-9-])\"\n",
    "- \".\" preceded by alphabetic lower or quote and followed by alphabetic upper or quote : \"(?<=[{al}{q}])\\.(?=[{au}{q}])\"\n",
    "- \",\" preceded by alphabetic and followed by alphabetic : \"(?<=[{a}]),(?=[{a}])\"\n",
    "- hyphen preceded by alphabetic and followed by alphabetic : \"(?<=[{a}])(?:{h})(?=[{a}])\"\n",
    "- \":\" \"<\" \">\" \"=\" \"/\" preceded by alphanumeric and followed by alphabetic : \"(?<=[{a}0-9])[:<>=/](?=[{a}])\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exceptions\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/tokenizer_exceptions.py\n",
    "\n",
    "TOKEN_MATCH (never split)\n",
    "\n",
    "- URL_PATTERN\n",
    "\n",
    "BASE_EXCEPTIONS\n",
    "\n",
    "- SPACE : space (32), non-breaking space (160), tab, \"\\t\", newline, \"\\n\", em dash (8212) => POS:SPACE\n",
    "- special cases : \\\\\"), &lt;space&gt;, '', C++\n",
    "- enumerations with letters :  \"a.\", \"b.\", …, \"z.\", \"\"ä.\", \"ö.\", \"ü.\"\n",
    "- emoticons\t: 126 combinations like \":-)\", \">:o\", \"^__^\", \"(ಠ_ಠ)\", \"¯\\(ツ)/¯\"\n",
    "\n",
    "Notes : \n",
    "\n",
    "- URL_PATTERN described here https://mathiasbynens.be/demo/url-regex with a few modifications.\n",
    "\n",
    "\n",
    "- emoticons - chars included : \": ; . - = * / \\ ^ _ ( ) \" ' [ ] { } < > | 0 1 3 8 D o O p P v V x X @ ¬ ಠ ︵ ¯ ツ ╯ ° □ ┻ ━\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French data\n",
    "\n",
    "### Char classes\n",
    "\n",
    "--> Combining Base data and French data <--\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/fr/punctuation.py\n",
    "\n",
    "ELISION = ' (39 Apostrophe) ’ (8217 Right Single Quotation Mark) \n",
    "\n",
    "HYPHENS = - (45 Hyphen-Minus) – (8211 En Dash) — (8212 Em Dash) ‐ (8208 Hyphen) ‑ (8209 Non-Breaking Hyphen)\n",
    "\n",
    "Notes - differences with Base version :\n",
    "\n",
    "- ELISION is new and specific to french\n",
    "\n",
    "\n",
    "- HYPHENS : REMOVED 45 Hyphen-Minus (2x 3x) | 8212 Em Dash (2x) | 126 Tilde, ADDED 8208 Hyphen | 8209 Non-Breaking Hyphen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefixes\n",
    "\n",
    "--> Using Base data <--\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/punctuation.py\n",
    "\n",
    "- punct, ellipses, quotes, currency, icons\n",
    "- \"§\" (167 Section Sign), \"%\", \"=\", \"—\" (8212 Em Dash), \"–\" (8211 En Dash)\n",
    "- \"+\" not followed by a number : \"\\+(?![0-9])+\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffixes\n",
    "\n",
    "--> Using French data <--\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/fr/punctuation.py\n",
    "  \n",
    "- punct, ellipses, quotes\n",
    "- \"+\" preceded by numbers : \"(?<=[0-9])\\+\"\t\t\n",
    "- \".\" preceded by temperature : \"(?<=°[FfCcKk])\\.\"\t\t\n",
    "- \".\" preceded by alphanumeric lower, \"%\" \"²\" \"-\" \"+\", quotes : \"(?<=[0-9{al}{e}(?:{q})])\\.\"\n",
    "- \".\" preceded by at least two alphabetic upper : \"(?<=[{au}][{au}])\\.\"\n",
    "- currency preceded by number : \"(?<=[0-9])(?:{c})\"\t\t\n",
    "- unit preceded by number : (?<=[0-9])(?:{u})\"\t\t\t\t\n",
    "- temperature unit after number : \"(?<=[0-9])°[FfCcKk]\"\n",
    "- % after number : \"(?<=[0-9])%\"\n",
    "\n",
    "Notes - differences with Base version :\n",
    "\n",
    "- REMOVED - icons *[seems needed in French too]*\n",
    "\n",
    "\n",
    "- REMOVED - english suffixes : \"'s\", \"'S\", \"’s\", \"’S\"\n",
    "\n",
    "\n",
    "- REMOVED - \"—\" (8212 Em Dash), \"–\" (8211 En Dash)\n",
    "\n",
    "\n",
    "- ADDED - temperature unit after number : \"(?<=[0-9])°[FfCcKk]\" *[seems needed in english too]*\n",
    "\n",
    "\n",
    "- ADDED : % after number : \"(?<=[0-9])%\" *[redundant with unit preceded by number, because unit contains %]*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infixes\n",
    "\n",
    "--> Combining Base data and French data <--\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/fr/punctuation.py\n",
    "\n",
    "\n",
    "French data :\n",
    "- (alphabetic elision) | alphabetic : \"(?<=[{a}][{el}])(?=[{a}])\"\t\n",
    "\n",
    "Base data :\n",
    "- ellipses, icons\n",
    "- \"+\" \"-\" \"\\*\" \"^\" preceded by number and followed by number or \"-\" : \"(?<=[0-9])[+\\-\\*^](?=[0-9-])\"\n",
    "- \".\" preceded by alphabetic lower or quote and followed by alphabetic upper or quote : \"(?<=[{al}{q}])\\.(?=[{au}{q}])\"\n",
    "- \",\" preceded by alphabetic and followed by alphabetic : \"(?<=[{a}]),(?=[{a}])\"\n",
    "- hyphen preceded by alphabetic and followed by alphabetic : \"(?<=[{a}])(?:{h})(?=[{a}])\"\n",
    "- \":\" \"<\" \">\" \"=\" \"/\" preceded by alphanumeric and followed by alphabetic : \"(?<=[{a}0-9])[:<>=/](?=[{a}])\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions\n",
    "\n",
    "--> Combining Base data and French data <--\n",
    "\n",
    "https://github.com/explosion/spaCy/blob/master/spacy/lang/fr/tokenizer_exceptions.py\n",
    "\n",
    "TOKEN_MATCH (never split)\n",
    "[in addition to URL_PATTERN]\n",
    "\n",
    "\\- char - Prefixes :\n",
    "\n",
    "- \"anti\", \n",
    "- \"apr[èe]s\", \"arrières?\", \"avant\", \"bas(?:ses?)?\",\n",
    "- \"am[ée]ricano\", \"anglo\", \"arabo\",\n",
    "-  \"a[ée]ro\", \"audio\",\n",
    "- \"abat\", \"a[fg]ro\", \"aigues?\", \"arcs?\", \"archi\", \"bec?\", \"banc\", \"blanc\",\n",
    "- \"avion\", \"bateaux?\", \"auto\", \"bio?\",\n",
    "- \"belles?\", \"beau\", \"bien\",\n",
    "- \"after\", \"best\",\n",
    "... 193 prefixes ...\n",
    "- Cities prefixes : \"Fontaine\", \"La Chapelle\", \"Marie\", \"Le Mesnil\", \"Neuville\", \"Pierre\", \"Val\", \"Vaux\"\n",
    "\n",
    "=> \"^{prefix}[{hyphen}][{al}][{hyphen}{al}{elision}]\\*$\"\n",
    "\n",
    "\\- char - Compound words :\n",
    "\n",
    "```\n",
    "\"^a[{hyphen}]sexualis[{al}]+$\", \"^binge[{hyphen}]watch[{al}]+$\", \"^black[{hyphen}]out[{al}]*$\", \"^bouche[{hyphen}]por[{al}]+$\", \"^burn[{hyphen}]out[{al}]*$\", .... 50 compound words ...... \"^teuf[{hyphen}]teuf[{al}]*$\", \"^yo[{hyphen}]yo[{al}]+$\", \"^zig[{hyphen}]zag[{al}]*$\", \"^z[{elision}]yeut[{al}]+$\"\n",
    "```\n",
    "\n",
    "\\- char - Double compound words (like saut-de-ski, pet-en-l'air) :\n",
    "\n",
    "- \"l[èe]s?\", \"la\", \"en\", \"des?\", \"d[eu]\", \"sur\", \"sous\", \"aux?\", \"à\", \"et\", \"près\", \"saint\"\n",
    "\n",
    "=> \"^[{a}]+[{hyphen}]{hyphen_combo}[{hyphen}](?:l[{elision}])?[{a}]+$\"\n",
    "\n",
    "\\' char - Prefixes :\n",
    "\n",
    "- \"r?é?entr\", \"grande?s?\", \"r\"\n",
    "\n",
    "=> \"^{prefix}[{elision}][{al}][{hyphen}{al}{elision}]\\*$\"\n",
    "\n",
    "TOKENIZER_EXCEPTIONS\n",
    "[in addition to Base data]\n",
    "\n",
    ". char - Dates :\n",
    "- \"janv.\" \"févr.\" \"avr.\" \"juill.\" \"sept.\" \"oct.\" \"nov.\" \"déc.\" => \"janvier\" ... \"décembre\"\n",
    "- \"av.\" \"apr.\" \"J.-C.\" => \"avant\" \"après\" \"Jésus\" \"Christ\"\n",
    "\n",
    ". char - Titles :\n",
    "- \"M.\" \"Mr.\" \"Mme.\" \"Mlle.\" \"Dr.\" => \"monsieur\" ... \"docteur\"\n",
    "- \"St.\" \"Ste.\" => \"saint\" \"sainte\"\n",
    "\n",
    ". char - Abbreviations :\n",
    "- \"etc.\"\n",
    "\n",
    "° char - Abbreviations :\n",
    "- \"n°\" \"d°\" => \"numéro\" \"degrés\"\n",
    "\n",
    "\\- char - \"-t-\" :\n",
    "- \"a\" \"est\" \"semble\" \"indique\" \"moque\" \"passe\" +++ \"-t\" +++ \"-elle\", \"-il\", \"-on\"\n",
    "\n",
    "\\- char - \"-ce\" :\n",
    "- \"est\" +++ \"-ce\"\n",
    "\n",
    "' and \\- chars :\n",
    "- \"qu'\" \"n'\" +++ \"est\" +++ \"-ce\"\n",
    "\n",
    "' char :\n",
    "- \"aujourd'hui\" \"Aujourd'hui\"\n",
    "\n",
    "\n",
    "Notes - suggested improvements :\n",
    "\n",
    "- for ' and - characters, we should generate all variants of the exceptions for HYPHENS chars and ELISION chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
